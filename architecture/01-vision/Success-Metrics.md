# Success Metrics

## üìã Prop√≥sito del Documento

Define las **m√©tricas concretas y medibles** que determinar√°n si el sistema cumple su prop√≥sito. Establece umbrales objetivos de √©xito o fallo. Es el contrato de calidad entre el equipo t√©cnico y el negocio.

## üéØ Qu√© Debe Contener

- M√©tricas t√©cnicas (SLIs, SLOs, SLAs)
- M√©tricas de negocio (conversi√≥n, revenue, engagement)
- M√©tricas de calidad (bugs, performance, disponibilidad)
- Umbrales de alerta y umbrales cr√≠ticos
- Frecuencia de medici√≥n y ownership

## üèóÔ∏è Impacto en la Arquitectura

- **Observabilidad**: Define qu√© instrumentar (logs, m√©tricas, trazas)
- **Alerting**: Establece qu√© monitorear proactivamente
- **Testing**: Determina qu√© validar antes de deploy
- **Capacity planning**: Gu√≠a decisiones de escalamiento

## ‚ö†Ô∏è Criticidad en Sistemas de Gran Escala

Sin m√©tricas claras:

- No se sabe cu√°ndo el sistema est√° fallando
- Los problemas se detectan cuando ya impactaron usuarios
- No hay datos para justificar mejoras t√©cnicas
- Imposible hacer post-mortems objetivos

---

## üìä Categor√≠as de M√©tricas

### 1. Service Level Indicators (SLIs)

**Definici√≥n**: M√©tricas t√©cnicas cuantitativas del comportamiento del servicio.

### 2. Service Level Objectives (SLOs)

**Definici√≥n**: Umbrales objetivo para los SLIs. Son compromisos internos del equipo.

### 3. Service Level Agreements (SLAs)

**Definici√≥n**: Compromisos contractuales con clientes. Violarlos tiene penalizaciones econ√≥micas.

**Relaci√≥n**: `SLA < SLO < Realidad` (el SLO debe tener margen vs el SLA)

---

## üéØ M√©tricas de Disponibilidad

### SLI: Availability

**F√≥rmula**: `(Requests exitosos / Total requests) √ó 100`

**Targets**:

- **SLO**: 99.9% uptime mensual = ~43 minutos downtime/mes
- **SLA**: 99.5% uptime mensual = ~3.6 horas downtime/mes
- **Target ideal**: 99.95% uptime

**Ventana de medici√≥n**: Rolling 30 d√≠as

**Exclusiones** (no cuentan contra disponibilidad):

- Mantenimientos programados (notificados 72h antes)
- Ataques DDoS masivos
- Fallos de proveedores cr√≠ticos (AWS outage regional)

**Penalizaciones por incumplimiento de SLA**:

- 99.5% - 99.0%: 10% cr√©dito del mes
- 99.0% - 98.0%: 25% cr√©dito del mes
- < 98.0%: 50% cr√©dito del mes

**Instrumentaci√≥n**:

```typescript
// Healthcheck endpoint obligatorio en cada microservicio
GET /health ‚Üí 200 OK (healthy) | 503 Service Unavailable (unhealthy)
```

**Monitoreo**: Prometheus + Alertmanager + PagerDuty

---

## ‚ö° M√©tricas de Performance

### SLI: Request Latency

**F√≥rmula**: Percentil 95 (P95) del tiempo de respuesta del API

**Targets por tipo de operaci√≥n**:

| Operaci√≥n        | P95 Target | P99 Target | Criticidad |
| ---------------- | ---------- | ---------- | ---------- |
| GET /products    | < 100ms    | < 300ms    | Alta       |
| POST /orders     | < 200ms    | < 500ms    | Cr√≠tica    |
| POST /payments   | < 500ms    | < 1000ms   | Cr√≠tica    |
| GET /orders/:id  | < 150ms    | < 400ms    | Media      |
| Admin operations | < 1000ms   | < 2000ms   | Baja       |

**Justificaci√≥n de targets**:

- Google recomienda < 200ms para buena UX
- Cada 100ms de latencia reduce conversi√≥n ~1%
- Operaciones cr√≠ticas (checkout) toleran m√°s latencia

**Instrumentaci√≥n**:

```typescript
// Middleware de timing en cada request
app.use((req, res, next) => {
  const start = Date.now();
  res.on('finish', () => {
    const duration = Date.now() - start;
    metrics.histogram('http_request_duration_ms', duration, {
      method: req.method,
      route: req.route?.path,
      status: res.statusCode,
    });
  });
  next();
});
```

**Alertas**:

- **Warning**: P95 > target por 10 minutos consecutivos
- **Critical**: P95 > 2√ó target por 5 minutos consecutivos

---

## üî• M√©tricas de Throughput

### SLI: Requests per Second (RPS)

**Descripci√≥n**: Capacidad de procesamiento del sistema

**Targets**:

- **M√≠nimo aceptable**: 100 RPS sostenido
- **Target operativo**: 500 RPS sostenido
- **Picos esperados**: 2,000 RPS durante 15 minutos (Black Friday)

**Crecimiento esperado**: +20% mensual en primeros 6 meses

**Dimensionamiento**:

- Cada instancia de microservicio: ~50 RPS
- Auto-scaling: escalar cuando CPU > 70% por 3 minutos
- M√≠nimo 2 r√©plicas por servicio (alta disponibilidad)

**Instrumentaci√≥n**:

```typescript
// Counter de requests por endpoint
metrics.counter('http_requests_total', {
  method: req.method,
  route: req.route?.path,
  status: res.statusCode,
});
```

---

## üí• M√©tricas de Error Rate

### SLI: Error Rate

**F√≥rmula**: `(Requests con 5xx / Total requests) √ó 100`

**Targets**:

- **SLO**: < 0.1% error rate (99.9% success rate)
- **SLA**: < 1% error rate (99% success rate)
- **Target ideal**: < 0.01% error rate

**Clasificaci√≥n de errores**:

| C√≥digo        | Tipo           | Cuenta contra SLO? | Acci√≥n               |
| ------------- | -------------- | ------------------ | -------------------- |
| 4xx (400-499) | Client error   | NO                 | Log para analytics   |
| 429           | Rate limiting  | NO                 | Esperado bajo ataque |
| 5xx (500-599) | Server error   | S√ç                 | Alerta inmediata     |
| Timeout       | Infrastructure | S√ç                 | Investigar latencia  |

**Instrumentaci√≥n**:

```typescript
// Error tracking
metrics.counter('http_errors_total', {
  method: req.method,
  route: req.route?.path,
  status: res.statusCode,
  error_type: error.constructor.name,
});
```

**Alertas**:

- **Warning**: Error rate > 0.5% por 5 minutos
- **Critical**: Error rate > 1% por 2 minutos
- **Page**: Error rate > 5% inmediatamente

---

## üîÑ M√©tricas de Deployment

### DORA Metrics

Medici√≥n de la madurez de ingenier√≠a del equipo.

#### 1. Deployment Frequency

**Target**: Al menos **5 deploys/semana** en producci√≥n

**Medici√≥n**: Conteo de merges a rama `main` que llegan a producci√≥n

**Benchmark**:

- Elite: Multiple deploys/d√≠a
- High: 1-6 deploys/semana ‚Üê **Nuestro target**
- Medium: 1-4 deploys/mes
- Low: < 1 deploy/mes

#### 2. Lead Time for Changes

**Target**: < **2 horas** desde commit hasta producci√≥n

**Medici√≥n**: Timestamp del commit ‚Üí timestamp del deploy exitoso

**Componentes**:

- Build time: < 10 minutos
- Test time: < 15 minutos
- Review time: < 4 horas (humano)
- Deploy time: < 5 minutos

#### 3. Change Failure Rate

**Target**: < **5%** de deploys causan incidente

**Medici√≥n**: (Deploys con rollback o hotfix / Total deploys) √ó 100

**Prevenci√≥n**:

- Testing automatizado > 80% coverage
- Feature flags para kill-switch
- Canary deployments (10% ‚Üí 50% ‚Üí 100%)

#### 4. Mean Time To Recovery (MTTR)

**Target**: < **1 hora** desde detecci√≥n hasta resoluci√≥n

**Medici√≥n**: Timestamp alerta ‚Üí timestamp servicio restaurado

**Estrategias**:

- Rollback automatizado en < 5 minutos
- Runbooks detallados por tipo de incidente
- On-call rotation con escalation clara

---

## üìà M√©tricas de Negocio

### Conversion Rate

**F√≥rmula**: `(√ìrdenes completadas / Sesiones con productos vistos) √ó 100`

**Target**: > 3% conversi√≥n

**Tracking**:

- Google Analytics + custom events
- Funnel: Landing ‚Üí Product View ‚Üí Add to Cart ‚Üí Checkout ‚Üí Payment ‚Üí Success

**Correlaci√≥n con m√©tricas t√©cnicas**:

- Latencia P95 < 200ms ‚Üí +1.5% conversi√≥n
- Error rate > 1% ‚Üí -5% conversi√≥n
- Downtime ‚Üí -100% conversi√≥n durante ventana

### Average Order Value (AOV)

**F√≥rmula**: `Total revenue / N√∫mero de √≥rdenes`

**Target**: > $50 USD

**M√©tricas relacionadas**:

- Productos por orden: > 2.5
- Uso de descuentos: < 30% de √≥rdenes

### Customer Lifetime Value (CLV)

**F√≥rmula**: `(Valor promedio de orden √ó Frecuencia de compra √ó Vida del cliente)`

**Target**: > $500 USD

**Tracking**: Cohort analysis mensual

---

## üß™ M√©tricas de Calidad del C√≥digo

### Code Coverage

**Target**: > **80%** l√≠neas cubiertas por tests

**Medici√≥n**: Jest/Vitest coverage reports

**Desglose por tipo de test**:

- Unit tests: > 85% coverage
- Integration tests: > 70% coverage
- E2E tests: Core flows cubiertos

**Enforcement**: CI/CD bloquea merge si coverage < 80%

### Technical Debt Ratio

**F√≥rmula**: `(Esfuerzo para remediar / Esfuerzo de desarrollo total) √ó 100`

**Target**: < **5%** (deuda bajo control)

**Medici√≥n**: SonarQube analysis

**Umbrales**:

- < 5%: Excelente (verde)
- 5-10%: Aceptable (amarillo)
- 10-20%: Preocupante (naranja)
- \> 20%: Cr√≠tico (rojo) - Bloquear features

### Bug Density

**F√≥rmula**: `Bugs encontrados en producci√≥n / 1000 l√≠neas de c√≥digo`

**Target**: < **0.5 bugs/KLOC**

**Clasificaci√≥n**:

- **P0 - Critical**: Sistema down o p√©rdida de datos
- **P1 - High**: Feature principal rota
- **P2 - Medium**: Bug menor con workaround
- **P3 - Low**: Mejora cosm√©tica

---

## üîê M√©tricas de Seguridad

### Security Incidents

**Target**: **0 incidentes cr√≠ticos de seguridad** al a√±o

**Clasificaci√≥n**:

- **Critical**: Data breach, credenciales expuestas
- **High**: Vulnerabilidad explotable detectada
- **Medium**: Configuraci√≥n insegura sin explotaci√≥n
- **Low**: Dependencia con CVE no cr√≠tico

**Medici√≥n**:

- OWASP ZAP scans semanales
- Dependabot alerts autom√°ticos
- Penetration testing trimestral

### Mean Time To Patch (MTTP)

**Target**: < **24 horas** para vulnerabilidades cr√≠ticas

**Proceso**:

1. Detecci√≥n de CVE
2. Evaluaci√≥n de impacto
3. Patch aplicado
4. Despliegue a producci√≥n
5. Validaci√≥n

---

## üìâ Umbrales y Alerting

### Niveles de Severidad

| Nivel         | Condici√≥n             | Notificaci√≥n        | SLA de respuesta |
| ------------- | --------------------- | ------------------- | ---------------- |
| **INFO**      | M√©tricas normales     | Dashboard           | N/A              |
| **WARNING**   | Tendencia preocupante | Slack               | 1 hora           |
| **ERROR**     | Umbral superado       | Slack + Email       | 30 minutos       |
| **CRITICAL**  | Servicio degradado    | PagerDuty (on-call) | 15 minutos       |
| **EMERGENCY** | Outage total          | PagerDuty + Phone   | 5 minutos        |

### Configuraci√≥n de Alertas

```yaml
# Ejemplo de alerta en Prometheus
groups:
  - name: api_latency
    interval: 30s
    rules:
      - alert: HighLatency
        expr: histogram_quantile(0.95, http_request_duration_ms) > 200
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: 'API latency P95 > 200ms'

      - alert: CriticalLatency
        expr: histogram_quantile(0.95, http_request_duration_ms) > 500
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: 'API latency P95 > 500ms - Immediate action required'
```

---

## üìä Dashboards Obligatorios

### 1. Executive Dashboard

**Audiencia**: Management, Product Owners

**M√©tricas**:

- Uptime actual (30 d√≠as)
- Transacciones/d√≠a
- Revenue/d√≠a
- Error rate
- P95 latency

**Actualizaci√≥n**: Tiempo real

### 2. Engineering Dashboard

**Audiencia**: Developers, DevOps

**M√©tricas**:

- RPS por servicio
- Error rate por endpoint
- Latency P50/P95/P99
- CPU/Memory usage
- Database query performance

**Actualizaci√≥n**: Cada 10 segundos

### 3. On-Call Dashboard

**Audiencia**: SRE, On-Call engineers

**M√©tricas**:

- Alertas activas
- Incidentes abiertos
- MTTR promedio
- Services health status
- Recent deployments

**Actualizaci√≥n**: Cada 5 segundos

---

## ‚úÖ Definici√≥n de "Done"

Un feature/epic se considera **DONE** cuando:

1. ‚úÖ Todos los tests pasan (unit, integration, e2e)
2. ‚úÖ Code coverage > 80%
3. ‚úÖ Code review aprobado por 2 seniors
4. ‚úÖ Documentaci√≥n actualizada
5. ‚úÖ M√©tricas instrumentadas (logs, traces, metrics)
6. ‚úÖ Alertas configuradas
7. ‚úÖ Runbook de troubleshooting creado
8. ‚úÖ Feature flag habilitado progresivamente
9. ‚úÖ Validaci√≥n en staging environment
10. ‚úÖ Deploy a producci√≥n exitoso + monitoreo por 48h

---

## üìÖ Revisi√≥n de M√©tricas

### Diaria (On-Call)

- Health checks de servicios
- Alertas activas
- Incidentes abiertos

### Semanal (Sprint Review)

- DORA metrics
- Feature velocity
- Bug burn-down

### Mensual (Leadership Review)

- SLI/SLO compliance
- Business KPIs
- Tech debt trends

### Trimestral (Strategy Review)

- SLA compliance
- ROI de inversiones t√©cnicas
- Roadmap de mejoras

---

**Versi√≥n**: 1.0  
**√öltima actualizaci√≥n**: Diciembre 2025  
**Aprobado por**: Tech Lead & SRE Lead  
**Pr√≥xima revisi√≥n**: Mensual
